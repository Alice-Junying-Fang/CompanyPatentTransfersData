{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import swifter\n",
    "import os\n",
    "from cleanco import cleanco\n",
    "import re\n",
    "import json\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "def name_preprocess(df, name):\n",
    "    df[name] = df[name].astype(str)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove commas\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\",\", \"\"))\n",
    "    \n",
    "    # Remove dot\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\".\", \"\"))\n",
    "    \n",
    "    # Remove *\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"*\", \"\"))\n",
    "    \n",
    "    # Remove !\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"!\", \"\"))\n",
    "    \n",
    "    # Remove ''\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"'\", \"\"))\n",
    "    \n",
    "    # Remove ;\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\";\", \"\"))\n",
    "    \n",
    "    # Remove /\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"/\", \"\"))\n",
    "\n",
    "    # Remove hyphens\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    \n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"(\", \"\"))\n",
    "    \n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\")\", \"\"))\n",
    "    \n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(\"&\", \"\"))\n",
    "\n",
    "    # Remove text between parenthesis\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.replace(r\"\\(.*\\)\", \"\"))\n",
    "\n",
    "    # Remove spaces in the begining/end\n",
    "    df[name] = df[name].swifter.apply(lambda x: x.strip())\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardized company names in the crosswalk\n",
    "#standardize words\n",
    "replacements = {'ac': 'action', 'assn': 'association', 'ass' : 'association', 'assoc': 'association',  'associations': 'association', 'associates': 'associate',\n",
    "    'cmte': 'committee',  'comm':'committee', 'com': 'committee',  'corp':'corporation','coporations': 'corporation', 'co':'company',\n",
    "    'companies':'company', 'citizen': 'citizens',  'employee': 'employees',  'enterprises': 'enterprise', 'fir': 'firm', 'grou':'group', \n",
    "     'govt': 'government', 'inst': 'institute', 'leag':'league', 'org': 'organization', 'organizations': 'organization',}\n",
    "\n",
    "def replace(match):\n",
    "    return replacements[match.group(0)]\n",
    "\n",
    "def replace_words(s):\n",
    "    return re.sub('|'.join(r'\\b%s\\b' % re.escape(s) for s in replacements),  replace, s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_words_company_name = ['association', 'bancorp', 'bancorporation', 'bank', 'company', 'corporate', 'corporation', \n",
    "                          'council','enterprise','foundation','group','inc','incorporated','institute',  'll, ''llc', 'llp', 'ltd', 'management', 'organization', \n",
    "                          'partners', 'pllc', 'services', 'utitlies']\n",
    "\n",
    "#cut words after word in the end_word_company_name list \n",
    "def cut_end_words(s, end_words_company_name_ = end_words_company_name):\n",
    "    for name in end_words_company_name_:\n",
    "        s = s.split(' ' + name + ' ')[0]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "#remove words\n",
    "    \n",
    "drop_words_list  = ['alabama', 'alabaman', 'alaska', 'alaskan', 'america', 'american', 'arizona', 'arizonan', 'arkansas', 'arkansasn', 'attorneys',\n",
    "                    'associate', 'association','bancorp', 'bancorporation', 'california', 'californian', 'center', 'ctr', 'company', 'coloradan', 'colorado',  'company', 'connecticut', 'connecticutan', 'corporation', 'delaware',\n",
    " 'construction', 'delawarean', 'employees','enterprise', 'family',  'families', 'federal', 'firm', 'florida', 'floridan', 'georgia', 'georgian',\n",
    "                    'group', 'hawaii', 'hawaiian', \n",
    "                    'holdings', 'idaho', 'idahoan', 'illinois', 'illinoisan',\n",
    " 'inc', 'incorporated', 'institute', 'indiana', 'indianan', 'international','iowa','iowan','kansas','kansasan','kentucky','kentuckyan', 'll', 'llc', 'llp',\n",
    " 'louisiana', 'louisianan', 'ltd', 'maine',  'mainean', 'maryland', 'marylandan', 'massachusetts', 'massachusettsan', 'michigan',\n",
    " 'michiganan', 'mid us', 'minnesota','minnesotan','mississippi','mississippian', 'missouri', 'missourian', 'montana','montanan',\n",
    " 'national', 'nebraska', 'nebraskan', 'nevada', 'nevadan','new hampshire','new jersey','new mexico','new york',\n",
    " 'nonpartisan', 'non partisan', 'north america', 'north carolina', 'north carolinians', 'north dakota', 'north dakotan', 'office',\n",
    " 'ohio', 'ohioan', 'oklahoma', 'oklahoman', 'operations', 'operating', 'oregon', 'oregonan', 'pac', 'partnership', 'pennsylvania','pennsylvanian','pllc',\n",
    "                    'properties', 'rhode island',\n",
    " 'rhode islandan','industries', 'service', 'services', 'south carolina', 'south carolinian', 'south dakota', 'south dakotan', 'supply', 'tennesean',\n",
    " 'tennessee','texan','texas', 'united states', 'us', 'usa', 'utah', 'utahan','vermont','vermontan','virginia','virginian','washington',\n",
    " 'washingtonan','west virginia', 'west virginian', 'wisconsin','wisconsinan', 'wyoming', 'wyomingan', 'svc', 'medical', 'solutions', 'energy', 'air', 'conditioning', 'research' , 'technology', 'los' , 'angeles',\n",
    "                'new york', 'guangzhou', 'beijing', 'shanghai', 'chicago','fuel', 'power', 'medical', 'products', \n",
    "                'systems', 'rotterdam', 'university', 'state', 'agricultural', 'universidad', 'generation', 'foods',\n",
    "                'food','semiconductor','acquisition', 'instrument', 'university', 'college', 'investment',\n",
    "                'east', 'west', 'europe', 'data','health', 'data', 'animal', 'performance', 'design', 'innovations', 'hk']\n",
    "\n",
    "stopwords = ['the', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very',\n",
    "            'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other',\n",
    "             'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these',\n",
    "             'your', 'his', 'through', 'don', 'nor',  'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up',\n",
    "             'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can',\n",
    "             'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those',\n",
    "         'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "\n",
    "drop_words_list1 = drop_words_list.copy()\n",
    "drop_words_list1.extend(stopwords)\n",
    "\n",
    "for i in list(pycountry.countries):\n",
    "    drop_words_list1.append(i.alpha_2.lower())\n",
    "    drop_words_list1.append(i.alpha_3.lower())\n",
    "    drop_words_list1.append(i.name.lower())\n",
    "    \n",
    "\n",
    "\n",
    "def remove_word(x):\n",
    "    x = x.split()\n",
    "    resultwords  = [word for word in x if word not in drop_words_list1]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_company_dataset(df_company2014, columnname = 'company'):\n",
    "    df_company2014 = name_preprocess(df_company2014, columnname)\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(replace_words)\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(cut_end_words)\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(remove_word)\n",
    "\n",
    "\n",
    "\n",
    "    #no need to drop duplicated values\n",
    "\n",
    "    df_company2014[columnname]  = df_company2014[columnname].swifter.apply(lambda x: x.strip())\n",
    "\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(lambda x: x.strip())\n",
    "\n",
    "    df_company2014[columnname]  = df_company2014[columnname].swifter.apply(lambda x: x.strip())\n",
    "    \n",
    "    df_company2014[columnname]  = df_company2014[columnname].swifter.apply(lambda x: x.strip())\n",
    "\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(lambda x: x.strip())\n",
    "    \n",
    "    #drop empty company values    \n",
    "    return df_company2014\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_company_dataset_1(df_company2014, columnname = 'company'):\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(lambda x: cleanco(x).clean_name())\n",
    "    df_company2014[columnname] = df_company2014[columnname].swifter.apply(lambda x: cleanco(x).clean_name())\n",
    "    #drop empty company values    \n",
    "    return df_company2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process patent transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\fjying\\\\Desktop\\\\RA_Columbia\\\\patentparsing\\\\notmeaningfultransfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('2013_01_notmeaningfultransfer.csv')\n",
    "file['assignor'] = file['assignor'].astype(str)\n",
    "companynames = np.unique(file['assignor'].dropna().values)\n",
    "\n",
    "for i in file.columns:\n",
    "    if i[0:4] == 'name':\n",
    "        file[i] = file[i].astype(str)\n",
    "        companynames = np.concatenate((companynames, np.unique(file[i].dropna().values)))\n",
    "companynames = np.unique(companynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[1:]:\n",
    "    file = pd.read_csv(file)\n",
    "    file['assignor'] = file['assignor'].astype(str)\n",
    "    companynames = np.concatenate((companynames, np.unique(file['assignor'].dropna().values)))\n",
    "    for i in file.columns:\n",
    "        if i[0:4] == 'name':\n",
    "            file[i] = file[i].astype(str)\n",
    "            companynames = np.concatenate((companynames, np.unique(file[i].dropna().values)))\n",
    "    companynames = np.unique(companynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\fjying\\\\Desktop\\\\RA_Columbia\\\\patentparsing\\\\identifycompanypermno\\\\intermediate_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames = pd.DataFrame(companynames, columns = ['company'])\n",
    "companynames.to_csv(\"patenttransfer_companynames.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames['rawcompany'] = companynames['company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames = process_company_dataset(companynames, 'company') \n",
    "companynames= process_company_dataset_1(companynames, 'company') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames.loc[companynames[companynames['company'] == ''].index, 'company'] = companynames[companynames['company'] == '']['rawcompany']\n",
    "companynames.loc[companynames[companynames['company'].isna()].index, 'company'] = companynames[companynames['company'].isna()]['rawcompany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames.to_csv(\"patenttransfer_companynames_standardized.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process first patent assignment\n",
    "firstpatentassignments  = pd.read_csv(\"first_patent_assignment_1980_2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpatentassignments['name_0'] = firstpatentassignments['name_0'].astype(str)\n",
    "firstpatentassignments['rawname_0'] = firstpatentassignments['name_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_0_unique = np.unique(firstpatentassignments['name_0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_0_unique = pd.DataFrame(name_0_unique, columns = ['name_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97fb485a29a47be85f1d4a8c7843d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a12cdafd884dce9baaee6ad11800ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8662f420b84c009b2299964265edf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930503d0ecc2437eb8c6a769a1e3fa9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29e60e4b3e843b1921357d6b9a1ff14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8db25295ef040cf967df9522248fdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eddc894fdab44f7b685dd09acb628f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19341b6efc64ebb90db7b89a670d8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6010e41c7b5f4be8b584f58883b5a801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f7043d83b04964a134e30a0089abb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff75b244b42e49e48ca303d31fe36186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831d13b4a4ad4d97bc8c71464306c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f99dabf20c4a8b8dfe7b52160730a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=377236.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name_0_unique = process_company_dataset(name_0_unique, 'name_0') \n",
    "name_0_unique= process_company_dataset_1(name_0_unique, 'name_0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_0_unique_raw_dict = dict(zip(list(name_0_unique['rawname_0'].values),list(name_0_unique['name_0'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpatentassignments['name_0']  = firstpatentassignments['rawname_0'].map(name_0_unique_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpatentassignments.loc[firstpatentassignments[firstpatentassignments['name_0']  == ''].index, 'name_0'] = firstpatentassignments[firstpatentassignments['name_0']  == '']['rawname_0']\n",
    "firstpatentassignments.loc[firstpatentassignments[firstpatentassignments['name_0'].isna()].index, 'name_0'] = firstpatentassignments[firstpatentassignments['name_0'].isna()]['rawname_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpatentassignments = firstpatentassignments[~firstpatentassignments['rawname_0'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpatentassignments.to_csv(\"first_patent_assignment_1980_2015_standardized.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.read_csv(\"first_patent_assignment_1980_2015_standardized.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
