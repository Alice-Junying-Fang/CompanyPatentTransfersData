{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from string_grouper import match_strings\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\fjying\\\\Desktop\\\\RA_Columbia\\\\patentparsing\\\\identifycompanypermno\\\\intermediate_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalks = pd.read_csv(\"permno_processedfirstassignorname_crosswalk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalks = crosswalks.rename(columns = {'name_0': 'company'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames = pd.read_csv(\"patenttransfer_companynames_standardized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_end_words(x, endwords):\n",
    "    words = x.split()\n",
    "    if words[-1] not in endwords or len(words) == 1:\n",
    "        return x\n",
    "    else:\n",
    "        return ' '.join(words[:-1])\n",
    "    \n",
    "def remove_words(x, endwords):\n",
    "    x = x.split()\n",
    "    resultwords  = [word for word in x if word not in endwords]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap_words(df):    \n",
    "    left_words = df['left_side'].split()\n",
    "    right_words = df['right_side'].split()\n",
    "    \n",
    "    if len(left_words)== 1 & len(right_words) == 1:\n",
    "        if df['left_side'] in df['right_side'] or df['right_side'] in df['left_side']:\n",
    "            return True\n",
    "        \n",
    "    intersects = len(set(left_words) & set(right_words))\n",
    "    \n",
    "    if (len(left_words) > len(right_words)) & (intersects/len(left_words) > 0.5):\n",
    "        return True\n",
    "    if (len(left_words) <= len(right_words)) & (intersects/len(right_words)> 0.5):\n",
    "        return True    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_words_name(df):\n",
    "    left_words = df['left_side'].split()\n",
    "    right_words = df['right_side'].split()\n",
    "\n",
    "    if  len(left_words)== 1 or len(right_words) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_companynames_permno_crosswalk(patenttransfer, crosswalks, column = 'company'):    \n",
    "    name_permno_dict = crosswalks.groupby('company')['permno'].apply(lambda g: g.values.tolist()).to_dict() \n",
    "    #exact match two companies\n",
    "    #automatically duplicate permnos for each row using the merge; consume many memories; instead using the list\n",
    "    patenttransfer['permno'] = patenttransfer[column].map(name_permno_dict)\n",
    "    \n",
    "    patenttransfer_aftermerge_notexactmatch = patenttransfer[patenttransfer['permno'].isna()]\n",
    "    patenttransfer_aftermerge_exactmatch = patenttransfer[~patenttransfer['permno'].isna()]\n",
    "    \n",
    "    print(\"percent of exact match\",\n",
    "           patenttransfer_aftermerge_exactmatch.shape[0]/patenttransfer.shape[0])\n",
    "    \n",
    "\n",
    "    #fuzzy match two companies\n",
    "    matches = match_strings(crosswalks['company'], patenttransfer_aftermerge_notexactmatch[column],\n",
    "                            max_n_matches = 1,min_similarity = 0.5)\n",
    "    matches = matches.sort_values(by = 'similarity', ascending = False)\n",
    "    \n",
    "    counts = matches['right_side'].apply(lambda x: x.split()[-1]).value_counts()\n",
    "    endwords_ = list(counts[counts>= 100].index)\n",
    "    counts = matches['left_side'].apply(lambda x: x.split()[-1]).value_counts()\n",
    "    endwords2 = list(counts[counts>= 100].index)\n",
    "    \n",
    "    endwords_.extend(endwords2)\n",
    "    \n",
    "    patenttransfer_aftermerge_notexactmatch[column]= patenttransfer_aftermerge_notexactmatch[column].swifter.apply(remove_end_words, endwords = endwords_)\n",
    "    patenttransfer_aftermerge_notexactmatch = patenttransfer_aftermerge_notexactmatch.drop_duplicates()\n",
    "\n",
    "    \n",
    "    crosswalks['company_remove_endwords'] = crosswalks['company'].swifter.apply(remove_end_words, endwords = endwords_)\n",
    "    crosswalks.loc[crosswalks[crosswalks['company_remove_endwords'] == ''].index, 'company_remove_endwords'] = crosswalks[crosswalks['company_remove_endwords'] == '']['company']\n",
    "    crosswalks.loc[crosswalks[crosswalks['company_remove_endwords'].isna()].index,'company_remove_endwords'] = crosswalks[crosswalks['company_remove_endwords'].isna()]['company']\n",
    "    \n",
    "    crosswalks_sub = crosswalks[['company_remove_endwords', 'permno']].drop_duplicates()\n",
    "    name_permno_dict_2 = crosswalks_sub.groupby('company_remove_endwords')['permno'].apply(lambda g: g.values.tolist()).to_dict()     \n",
    "    \n",
    "    \n",
    "    patenttransfer_aftermerge_notexactmatch['permno'] = patenttransfer_aftermerge_notexactmatch[column].map(name_permno_dict_2)\n",
    "    \n",
    "\n",
    "    patenttransfer_aftermerge_exactmatch = patenttransfer_aftermerge_exactmatch.append(patenttransfer_aftermerge_notexactmatch\n",
    "        [(~patenttransfer_aftermerge_notexactmatch['permno'].isna())])\n",
    "        \n",
    "    patenttransfer_aftermerge_notexactmatch = patenttransfer_aftermerge_notexactmatch\n",
    "    [(patenttransfer_aftermerge_notexactmatch['permno'].isna())]\n",
    "    \n",
    "    print(\"improved percent of exact match\", patenttransfer_aftermerge_exactmatch.shape[0]/patenttransfer.shape[0])\n",
    "    del patenttransfer\n",
    "\n",
    "    \n",
    "    #fuzzy match again based on refine company names\n",
    "    matches = match_strings(crosswalks_sub['company_remove_endwords'], patenttransfer_aftermerge_notexactmatch[column], max_n_matches = 1,min_similarity = 0.5)\n",
    "    \n",
    "    matches_exact = matches[matches['similarity'] > 0.99999999]\n",
    "    matches_notexact = matches[matches['similarity'] <=0.99999999]\n",
    "    \n",
    "    matches_notexact['overlap'] = matches_notexact.swifter.apply(find_overlap_words, axis = 1)\n",
    "    matches_overlap = matches_notexact[matches_notexact['overlap']]\n",
    "    matches_nonoverlap = matches_notexact[~matches_notexact['overlap']]\n",
    "    \n",
    "    matches_nonoverlap = matches_nonoverlap[~ matches_nonoverlap.swifter.apply(single_words_name, axis = 1)]\n",
    "    #<0.8: keep if words have duplicate more than two; country name\n",
    "    matches_final = pd.concat([matches_overlap,matches_nonoverlap[matches_nonoverlap['similarity']>= 0.8]])\n",
    "    matches_final = pd.concat([matches_exact, matches_final])\n",
    "    \n",
    "    matches_final = matches_final.drop(columns = ['overlap'], axis = 1)\n",
    "    matches_cut = matches_final.sort_values(by='similarity', ascending=False).drop_duplicates(subset = ['left_side', 'right_side'], keep = 'first')\n",
    "    matches_cut = pd.merge(matches_cut, crosswalks_sub, left_on = 'left_side', right_on ='company_remove_endwords', how = 'left')\n",
    "    \n",
    "    matches_cut = matches_cut[['permno', 'right_side']].drop_duplicates()\n",
    "    name_permno_dict_3 =matches_cut.groupby('right_side')['permno'].apply(lambda g: g.values.tolist()).to_dict()     \n",
    "    patenttransfer_aftermerge_notexactmatch['permno'] = patenttransfer_aftermerge_notexactmatch[column].map(name_permno_dict_3)\n",
    "    patenttransfer_aftermerge_exactmatch = patenttransfer_aftermerge_exactmatch.append(patenttransfer_aftermerge_notexactmatch)\n",
    "    \n",
    "    \n",
    "    patenttransfer_aftermerge_exactmatch = patenttransfer_aftermerge_exactmatch.drop_duplicates([column])\n",
    "    patenttransfer_aftermerge_exactmatch = patenttransfer_aftermerge_exactmatch.dropna()\n",
    "    return patenttransfer_aftermerge_exactmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames['company'] = companynames['company'].astype(str)\n",
    "crosswalks['company'] = crosswalks['company'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of exact match 0.0038425066120243516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1398b6331d456aaaea7a9e0aafdcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1593590.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fjying\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8690e6a4aa0f43b9955ea242b7655b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=2207.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "improved percent of exact match 0.0038425066120243516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f164c0b83774fc7ab79d2f232127393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1893.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fjying\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8952a202a77b4b2abef34d533b51584a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1123.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "companynames=   build_companynames_permno_crosswalk(companynames, crosswalks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_not_unique_permno(x):\n",
    "    if len(x) > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "companynames.to_csv(\"permno_processedallcompanyames_crosswalk.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
